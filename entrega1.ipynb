{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f133d3c5",
   "metadata": {},
   "source": [
    "# Nosso Trabalho :D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43935a43",
   "metadata": {},
   "source": [
    "## Parte 0: Bibliotecas e Configurações de Ambiente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06439bcc",
   "metadata": {},
   "source": [
    "Execute este comando abaixo se for necessário instalar as bibliotecas, lembrando que estamos utilizando o Python 3.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0d140c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch@ https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl\n",
      "  Using cached https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl (768.5 MB)\n",
      "Collecting torchaudio@ https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl\n",
      "  Using cached https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
      "Collecting torchvision@ https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp311-cp311-linux_x86_64.whl\n",
      "  Using cached https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp311-cp311-linux_x86_64.whl (7.3 MB)\n",
      "Requirement already satisfied: matplotlib==3.10.0 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (3.10.0)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (0.1.7)\n",
      "Requirement already satisfied: matplotlib-venn==1.1.2 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (1.1.2)\n",
      "Requirement already satisfied: numpy==1.26.4 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (1.26.4)\n",
      "Requirement already satisfied: nltk==3.9.1 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (3.9.1)\n",
      "Requirement already satisfied: opencv-contrib-python==4.11.0.86 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (4.11.0.86)\n",
      "Requirement already satisfied: opencv-python==4.11.0.86 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (4.11.0.86)\n",
      "Requirement already satisfied: opencv-python-headless==4.11.0.86 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (4.11.0.86)\n",
      "Requirement already satisfied: pandas==2.2.2 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (2.2.2)\n",
      "Requirement already satisfied: pandas-datareader==0.10.0 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (0.10.0)\n",
      "Requirement already satisfied: pandas-gbq==0.29.1 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (0.29.1)\n",
      "Requirement already satisfied: pandas-stubs==2.2.2.240909 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (2.2.2.240909)\n",
      "Requirement already satisfied: pillow==11.2.1 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 13)) (11.2.1)\n",
      "Collecting seaborn==0.13.2\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Requirement already satisfied: sklearn-compat==0.1.3 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 15)) (0.1.3)\n",
      "Requirement already satisfied: sklearn-pandas==2.2.0 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 16)) (2.2.0)\n",
      "Requirement already satisfied: torchao==0.10.0 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 18)) (0.10.0)\n",
      "Requirement already satisfied: torchcam==0.4.0 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 20)) (0.4.0)\n",
      "Requirement already satisfied: torchdata==0.11.0 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 21)) (0.11.0)\n",
      "Requirement already satisfied: torchsummary==1.5.1 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 22)) (1.5.1)\n",
      "Requirement already satisfied: torchtune==0.6.1 in ./.venv/lib/python3.11/site-packages (from -r requirements.txt (line 23)) (0.6.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib==3.10.0->-r requirements.txt (line 1)) (3.2.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib==3.10.0->-r requirements.txt (line 1)) (1.4.8)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.11/site-packages (from matplotlib==3.10.0->-r requirements.txt (line 1)) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.11/site-packages (from matplotlib==3.10.0->-r requirements.txt (line 1)) (4.58.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.11/site-packages (from matplotlib==3.10.0->-r requirements.txt (line 1)) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.11/site-packages (from matplotlib==3.10.0->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.11/site-packages (from matplotlib==3.10.0->-r requirements.txt (line 1)) (0.12.1)\n",
      "Requirement already satisfied: traitlets in ./.venv/lib/python3.11/site-packages (from matplotlib-inline==0.1.7->-r requirements.txt (line 2)) (5.14.3)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.11/site-packages (from matplotlib-venn==1.1.2->-r requirements.txt (line 3)) (1.16.0)\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.11/site-packages (from nltk==3.9.1->-r requirements.txt (line 5)) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.11/site-packages (from nltk==3.9.1->-r requirements.txt (line 5)) (2024.11.6)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.11/site-packages (from nltk==3.9.1->-r requirements.txt (line 5)) (8.2.1)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.11/site-packages (from nltk==3.9.1->-r requirements.txt (line 5)) (4.67.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.11/site-packages (from pandas==2.2.2->-r requirements.txt (line 9)) (2025.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas==2.2.2->-r requirements.txt (line 9)) (2025.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./.venv/lib/python3.11/site-packages (from pandas-datareader==0.10.0->-r requirements.txt (line 10)) (2.32.4)\n",
      "Requirement already satisfied: lxml in ./.venv/lib/python3.11/site-packages (from pandas-datareader==0.10.0->-r requirements.txt (line 10)) (5.4.0)\n",
      "Requirement already satisfied: google-cloud-bigquery<4.0.0,>=3.4.2 in ./.venv/lib/python3.11/site-packages (from pandas-gbq==0.29.1->-r requirements.txt (line 11)) (3.34.0)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=2.10.2 in ./.venv/lib/python3.11/site-packages (from pandas-gbq==0.29.1->-r requirements.txt (line 11)) (2.25.1)\n",
      "Requirement already satisfied: google-auth>=2.13.0 in ./.venv/lib/python3.11/site-packages (from pandas-gbq==0.29.1->-r requirements.txt (line 11)) (2.40.3)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.11/site-packages (from pandas-gbq==0.29.1->-r requirements.txt (line 11)) (59.6.0)\n",
      "Requirement already satisfied: google-auth-oauthlib>=0.7.0 in ./.venv/lib/python3.11/site-packages (from pandas-gbq==0.29.1->-r requirements.txt (line 11)) (1.2.2)\n",
      "Requirement already satisfied: db-dtypes<2.0.0,>=1.0.4 in ./.venv/lib/python3.11/site-packages (from pandas-gbq==0.29.1->-r requirements.txt (line 11)) (1.4.3)\n",
      "Requirement already satisfied: pydata-google-auth>=1.5.0 in ./.venv/lib/python3.11/site-packages (from pandas-gbq==0.29.1->-r requirements.txt (line 11)) (1.9.1)\n",
      "Requirement already satisfied: pyarrow>=4.0.0 in ./.venv/lib/python3.11/site-packages (from pandas-gbq==0.29.1->-r requirements.txt (line 11)) (20.0.0)\n",
      "Requirement already satisfied: types-pytz>=2022.1.1 in ./.venv/lib/python3.11/site-packages (from pandas-stubs==2.2.2.240909->-r requirements.txt (line 12)) (2025.2.0.20250516)\n",
      "Requirement already satisfied: scikit-learn<1.7,>=1.2 in ./.venv/lib/python3.11/site-packages (from sklearn-compat==0.1.3->-r requirements.txt (line 15)) (1.6.1)\n",
      "Requirement already satisfied: urllib3>=1.25 in ./.venv/lib/python3.11/site-packages (from torchdata==0.11.0->-r requirements.txt (line 21)) (2.5.0)\n",
      "Requirement already satisfied: huggingface_hub[hf_transfer] in ./.venv/lib/python3.11/site-packages (from torchtune==0.6.1->-r requirements.txt (line 23)) (0.33.0)\n",
      "Requirement already satisfied: datasets in ./.venv/lib/python3.11/site-packages (from torchtune==0.6.1->-r requirements.txt (line 23)) (3.6.0)\n",
      "Requirement already satisfied: sentencepiece in ./.venv/lib/python3.11/site-packages (from torchtune==0.6.1->-r requirements.txt (line 23)) (0.2.0)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.11/site-packages (from torchtune==0.6.1->-r requirements.txt (line 23)) (7.0.0)\n",
      "Requirement already satisfied: tiktoken in ./.venv/lib/python3.11/site-packages (from torchtune==0.6.1->-r requirements.txt (line 23)) (0.9.0)\n",
      "Requirement already satisfied: kagglehub in ./.venv/lib/python3.11/site-packages (from torchtune==0.6.1->-r requirements.txt (line 23)) (0.3.12)\n",
      "Requirement already satisfied: safetensors in ./.venv/lib/python3.11/site-packages (from torchtune==0.6.1->-r requirements.txt (line 23)) (0.5.3)\n",
      "Requirement already satisfied: tokenizers in ./.venv/lib/python3.11/site-packages (from torchtune==0.6.1->-r requirements.txt (line 23)) (0.21.1)\n",
      "Requirement already satisfied: blobfile>=2 in ./.venv/lib/python3.11/site-packages (from torchtune==0.6.1->-r requirements.txt (line 23)) (3.0.0)\n",
      "Requirement already satisfied: omegaconf in ./.venv/lib/python3.11/site-packages (from torchtune==0.6.1->-r requirements.txt (line 23)) (2.3.0)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./.venv/lib/python3.11/site-packages (from torch@ https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl->-r requirements.txt (line 17)) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./.venv/lib/python3.11/site-packages (from torch@ https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl->-r requirements.txt (line 17)) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./.venv/lib/python3.11/site-packages (from torch@ https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl->-r requirements.txt (line 17)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.venv/lib/python3.11/site-packages (from torch@ https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl->-r requirements.txt (line 17)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in ./.venv/lib/python3.11/site-packages (from torch@ https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl->-r requirements.txt (line 17)) (0.6.2)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./.venv/lib/python3.11/site-packages (from torch@ https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl->-r requirements.txt (line 17)) (11.2.1.3)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.11/site-packages (from torch@ https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl->-r requirements.txt (line 17)) (2025.3.0)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from torch@ https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl->-r requirements.txt (line 17)) (3.1.6)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.11/site-packages (from torch@ https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl->-r requirements.txt (line 17)) (3.5)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.11/site-packages (from torch@ https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl->-r requirements.txt (line 17)) (4.14.0)\n",
      "Requirement already satisfied: triton==3.2.0 in ./.venv/lib/python3.11/site-packages (from torch@ https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl->-r requirements.txt (line 17)) (3.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./.venv/lib/python3.11/site-packages (from torch@ https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl->-r requirements.txt (line 17)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./.venv/lib/python3.11/site-packages (from torch@ https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl->-r requirements.txt (line 17)) (12.4.5.8)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.11/site-packages (from torch@ https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl->-r requirements.txt (line 17)) (1.13.1)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from torch@ https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl->-r requirements.txt (line 17)) (3.18.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./.venv/lib/python3.11/site-packages (from torch@ https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl->-r requirements.txt (line 17)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./.venv/lib/python3.11/site-packages (from torch@ https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl->-r requirements.txt (line 17)) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./.venv/lib/python3.11/site-packages (from torch@ https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl->-r requirements.txt (line 17)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.venv/lib/python3.11/site-packages (from torch@ https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl->-r requirements.txt (line 17)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./.venv/lib/python3.11/site-packages (from torch@ https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl->-r requirements.txt (line 17)) (12.4.127)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.11/site-packages (from sympy==1.13.1->torch@ https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl->-r requirements.txt (line 17)) (1.3.0)\n",
      "Requirement already satisfied: pycryptodomex>=3.8 in ./.venv/lib/python3.11/site-packages (from blobfile>=2->torchtune==0.6.1->-r requirements.txt (line 23)) (3.23.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in ./.venv/lib/python3.11/site-packages (from google-api-core<3.0.0,>=2.10.2->pandas-gbq==0.29.1->-r requirements.txt (line 11)) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in ./.venv/lib/python3.11/site-packages (from google-api-core<3.0.0,>=2.10.2->pandas-gbq==0.29.1->-r requirements.txt (line 11)) (6.31.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in ./.venv/lib/python3.11/site-packages (from google-api-core<3.0.0,>=2.10.2->pandas-gbq==0.29.1->-r requirements.txt (line 11)) (1.70.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.venv/lib/python3.11/site-packages (from google-auth>=2.13.0->pandas-gbq==0.29.1->-r requirements.txt (line 11)) (4.9.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.11/site-packages (from google-auth>=2.13.0->pandas-gbq==0.29.1->-r requirements.txt (line 11)) (0.4.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./.venv/lib/python3.11/site-packages (from google-auth>=2.13.0->pandas-gbq==0.29.1->-r requirements.txt (line 11)) (5.5.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./.venv/lib/python3.11/site-packages (from google-auth-oauthlib>=0.7.0->pandas-gbq==0.29.1->-r requirements.txt (line 11)) (2.0.0)\n",
      "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in ./.venv/lib/python3.11/site-packages (from google-cloud-bigquery<4.0.0,>=3.4.2->pandas-gbq==0.29.1->-r requirements.txt (line 11)) (2.7.2)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in ./.venv/lib/python3.11/site-packages (from google-cloud-bigquery<4.0.0,>=3.4.2->pandas-gbq==0.29.1->-r requirements.txt (line 11)) (2.4.3)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib==3.10.0->-r requirements.txt (line 1)) (1.17.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests>=2.19.0->pandas-datareader==0.10.0->-r requirements.txt (line 10)) (2025.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests>=2.19.0->pandas-datareader==0.10.0->-r requirements.txt (line 10)) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests>=2.19.0->pandas-datareader==0.10.0->-r requirements.txt (line 10)) (3.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn<1.7,>=1.2->sklearn-compat==0.1.3->-r requirements.txt (line 15)) (3.6.0)\n",
      "Requirement already satisfied: xxhash in ./.venv/lib/python3.11/site-packages (from datasets->torchtune==0.6.1->-r requirements.txt (line 23)) (3.5.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.venv/lib/python3.11/site-packages (from datasets->torchtune==0.6.1->-r requirements.txt (line 23)) (0.3.8)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./.venv/lib/python3.11/site-packages (from datasets->torchtune==0.6.1->-r requirements.txt (line 23)) (0.70.16)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.11/site-packages (from datasets->torchtune==0.6.1->-r requirements.txt (line 23)) (6.0.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./.venv/lib/python3.11/site-packages (from huggingface_hub[hf_transfer]->torchtune==0.6.1->-r requirements.txt (line 23)) (1.1.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->torch@ https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl->-r requirements.txt (line 17)) (3.0.2)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in ./.venv/lib/python3.11/site-packages (from omegaconf->torchtune==0.6.1->-r requirements.txt (line 23)) (4.9.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./.venv/lib/python3.11/site-packages (from fsspec->torch@ https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl->-r requirements.txt (line 17)) (3.12.13)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.49.1 in ./.venv/lib/python3.11/site-packages (from google-api-core<3.0.0,>=2.10.2->pandas-gbq==0.29.1->-r requirements.txt (line 11)) (1.73.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.49.1 in ./.venv/lib/python3.11/site-packages (from google-api-core<3.0.0,>=2.10.2->pandas-gbq==0.29.1->-r requirements.txt (line 11)) (1.73.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in ./.venv/lib/python3.11/site-packages (from google-resumable-media<3.0.0,>=2.0.0->google-cloud-bigquery<4.0.0,>=3.4.2->pandas-gbq==0.29.1->-r requirements.txt (line 11)) (1.7.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in ./.venv/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.13.0->pandas-gbq==0.29.1->-r requirements.txt (line 11)) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./.venv/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.7.0->pandas-gbq==0.29.1->-r requirements.txt (line 11)) (3.3.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch@ https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl->-r requirements.txt (line 17)) (0.3.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch@ https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl->-r requirements.txt (line 17)) (1.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch@ https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl->-r requirements.txt (line 17)) (6.5.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch@ https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl->-r requirements.txt (line 17)) (1.20.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch@ https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl->-r requirements.txt (line 17)) (25.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch@ https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl->-r requirements.txt (line 17)) (2.6.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch@ https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl->-r requirements.txt (line 17)) (1.7.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1835956e",
   "metadata": {},
   "source": [
    "Vamos importar nossas bibliotecas essenciais primeiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0459b5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from torchcam.methods import SmoothGradCAMpp\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c86a93f",
   "metadata": {},
   "source": [
    "Dependendo do ambiente de execução, o hardware pode ser outro, então precisamos tirar qual device está sendo usado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b596f4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a710ae",
   "metadata": {},
   "source": [
    "Natural Language Toolkit (nltk):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bbbdf02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/xoxoluxa/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/xoxoluxa/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bdb842",
   "metadata": {},
   "source": [
    "## Parte 1: Funções Auxiliares e Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8d4306",
   "metadata": {},
   "source": [
    "### Funções"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460ba97f",
   "metadata": {},
   "source": [
    "NLTK: Limpeza de texto por stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab4e7a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stemmer = PorterStemmer()\n",
    "    text = text.lower()\n",
    "    tokens = re.findall(r'\\b\\w+\\b', text)\n",
    "    cleaned = []\n",
    "    for tok in tokens:\n",
    "        if tok in stop_words:\n",
    "            continue\n",
    "        cleaned.append(stemmer.stem(tok))\n",
    "    return ' '.join(cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922fb55d",
   "metadata": {},
   "source": [
    "Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f920ed18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,optimizer,criterion,train_loader,val_loader,num_epochs=10):\n",
    "    \"\"\"\n",
    "    Executa o treinamento e validação por num_epochs e depois\n",
    "    retorna 4 listas: train_losses, train_accs, val_losses e val_accs.\n",
    "    \"\"\"\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0\n",
    "        running_total = 0\n",
    "\n",
    "        # Itera sobre batches de treino, sendo que o loader retorna (images, labels, caption)\n",
    "        for images, labels, _ in train_loader:\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Acumula loss\n",
    "            batch_size = images.size(0)\n",
    "            running_loss += loss.item() * batch_size\n",
    "\n",
    "            # Acumula acertos para train acc\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            running_correct += (preds == labels).sum().item()\n",
    "            running_total += batch_size\n",
    "\n",
    "\n",
    "        epoch_train_loss = running_loss / running_total\n",
    "        epoch_train_acc = running_correct / running_total\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        train_accs.append(epoch_train_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.4f}\")\n",
    "\n",
    "        ## Etapa de avaliação\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        val_running_correct = 0\n",
    "        val_running_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels, _ in val_loader:\n",
    "                images = images.to(device, non_blocking=True)\n",
    "                labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                batch_size = images.size(0)\n",
    "                val_running_loss += loss.item() * batch_size\n",
    "\n",
    "                _, preds = torch.max(outputs, dim=1)\n",
    "                val_running_correct += (preds == labels).sum().item()\n",
    "                val_running_total += batch_size\n",
    "\n",
    "        epoch_val_loss = val_running_loss / val_running_total\n",
    "        epoch_val_acc = val_running_correct / val_running_total\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        val_accs.append(epoch_val_acc)\n",
    "\n",
    "        print(f\"           Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_acc:.4f}\")\n",
    "    return train_losses, train_accs, val_losses, val_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b0e89e",
   "metadata": {},
   "source": [
    "Plot avaliador de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1bb3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trainval_graphs(train_losses, train_accs, val_losses, val_accs):\n",
    "  epochs_range = range(1, len(train_losses) + 1)\n",
    "\n",
    "  plt.figure(figsize=(8, 4))\n",
    "  plt.plot(epochs_range, train_losses, label='Train Loss')\n",
    "  plt.plot(epochs_range, val_losses, label='Val Loss')\n",
    "  plt.xlabel('Época')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.title('Loss por Época')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "  plt.show()\n",
    "\n",
    "  plt.figure(figsize=(8, 4))\n",
    "  plt.plot(epochs_range, train_accs, label='Train Acc')\n",
    "  plt.plot(epochs_range, val_accs, label='Val Acc')\n",
    "  plt.xlabel('Época')\n",
    "  plt.ylabel('Acurácia')\n",
    "  plt.title('Acurácia por Época')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d908ee96",
   "metadata": {},
   "source": [
    "Subfunção Precisão por Classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6305aca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_per_class(model,loader):\n",
    "  acc_count = np.zeros(len(classes)) ## conta casos em que pred==truelabel (acertou predizendo a classe X)\n",
    "  error_count = np.zeros(len(classes)) ## conta casos em que predizeu X e a classe era Y, nesse caso error_count[X]+=1 (errou predizendo a classe X)\n",
    "  total_class_count = np.zeros(len(classes))\n",
    "  \n",
    "  for images, labels_true, captions in loader:\n",
    "    images = images.to(device, non_blocking=True)\n",
    "\n",
    "    outputs = model(images)\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "    for i,label_true in enumerate(labels_true):\n",
    "      if int(label_true) == int(preds[i]):\n",
    "        acc_count[label_true]+=1\n",
    "      else:\n",
    "        error_count[int(preds[i])]+=1\n",
    "      total_class_count[label_true]+=1\n",
    "    acc_count /= total_class_count\n",
    "    error_count /= sum(error_count) ## normaliza para todas as predições\n",
    "  return acc_count,error_count ## (acurácia por classe , proporções de predições feitas erradas por classe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfab8f30",
   "metadata": {},
   "source": [
    "Plotter de precisão por Classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1be2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acc_per_class(model,loaders:list):\n",
    "  \"\"\"\n",
    "  Plota o gráfico de acurácia por classe para os dados de treino, validação e teste.\n",
    "  Args:\n",
    "    loaders (list): lista de loaders (train_loader, val_loader, test_loader)\n",
    "    dfs (list): lista de dataframes (df_train, df_val, df_test)\n",
    "  \"\"\"\n",
    "  fig,axs = plt.subplots(2,3,figsize=(6*3,4*2))\n",
    "  plt.title(\"Acurácia e erro por classe\")\n",
    "\n",
    "  train_acc_perclass,train_error_perclass = get_acc_per_class(model,train_loader)\n",
    "  ax = axs[0][0]\n",
    "  ax.set_title(\"Acertou predizendo [train]\")\n",
    "  ax.bar(np.arange(len(classes)),train_acc_perclass)\n",
    "  ax.set_ylabel(\"% de acerto\")\n",
    "  ax.set_xticks(np.arange(len(classes)),classes)\n",
    "  ax = axs[1][0]\n",
    "  ax.set_title(\"Errou predizendo [train]\")\n",
    "  ax.bar(np.arange(len(classes)),train_error_perclass)\n",
    "  ax.set_ylabel(\"proporção da predição\")\n",
    "  ax.set_xticks(np.arange(len(classes)),classes)\n",
    "\n",
    "  val_acc_perclass,val_error_perclass = get_acc_per_class(model,val_loader)\n",
    "  ax = axs[0][1]\n",
    "  ax.set_title(\"Acertou predizendo [val]\")\n",
    "  ax.bar(np.arange(len(classes)),val_acc_perclass)\n",
    "  ax.set_ylabel(\"% de acerto\")\n",
    "  ax.set_xticks(np.arange(len(classes)),classes)\n",
    "  ax = axs[1][1]\n",
    "  ax.set_title(\"Errou predizendo [val]\")\n",
    "  ax.bar(np.arange(len(classes)),val_error_perclass)\n",
    "  ax.set_ylabel(\"proporção da predição\")\n",
    "  ax.set_xticks(np.arange(len(classes)),classes)\n",
    "\n",
    "  test_acc_perclass,test_error_perclass = get_acc_per_class(model,test_loader)\n",
    "  ax = axs[0][2]\n",
    "  ax.set_title(\"Acertou predizendo [test]\")\n",
    "  ax.bar(np.arange(len(classes)),test_acc_perclass)\n",
    "  ax.set_ylabel(\"% de acerto\")\n",
    "  ax.set_xticks(np.arange(len(classes)),classes)\n",
    "  ax = axs[1][2]\n",
    "  ax.set_title(\"Errou predizendo [test]\")\n",
    "  ax.bar(np.arange(len(classes)),test_error_perclass)\n",
    "  ax.set_ylabel(\"proporção da predição\")\n",
    "  ax.set_xticks(np.arange(len(classes)),classes)\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "  train_labels = [element[1] for element in train_dataset]\n",
    "  val_labels = [element[1] for element in train_dataset]\n",
    "  test_labels = [element[1] for element in train_dataset]\n",
    "\n",
    "  print(\"\\nQuantidade de labels em cada conjunto: \")\n",
    "  print(\"Treino   : \",np.unique(train_labels,return_counts=True))\n",
    "  print(\"Validação: \",np.unique(test_labels,return_counts=True))\n",
    "  print(\"Teste    : \",np.unique(val_labels,return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d903c55",
   "metadata": {},
   "source": [
    "TorchCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3865289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cam_img(model,target_layer,input_tensor,threshold=90,alpha = 0.9):\n",
    "  cam_extractor = SmoothGradCAMpp(model, target_layer=target_layer)\n",
    "  with torch.enable_grad():\n",
    "      output = model(input_tensor)\n",
    "  class_idx = output.squeeze(0).argmax().item()\n",
    "\n",
    "  activation_maps = cam_extractor(class_idx, output)\n",
    "  activation_map = activation_maps[0] if isinstance(activation_maps, list) else activation_maps\n",
    "  if activation_map.ndim == 3 and activation_map.shape[0] == 1:\n",
    "      activation_map = activation_map.squeeze(0)  # de (1,H,W) para (H,W)\n",
    "\n",
    "  cam = activation_map.unsqueeze(0).unsqueeze(0)  # (1,1,H,W)\n",
    "  cam_upsampled = F.interpolate(cam, size=(224,224), mode='bilinear', align_corners=False)\n",
    "  cam_np = cam_upsampled.squeeze().cpu().detach().numpy()  # (224,224)\n",
    "  cam_np -= cam_np.min()\n",
    "  if cam_np.max() > 0:\n",
    "      cam_np /= cam_np.max()\n",
    "\n",
    "  img_np = input_tensor.squeeze(0).cpu().detach().numpy().transpose(1,2,0)\n",
    "  threshold = np.percentile(cam_np, threshold)\n",
    "  mask = cam_np > threshold\n",
    "\n",
    "  cmap = plt.cm.viridis\n",
    "  alpha = np.clip((cam_np - threshold) / (1 - threshold), 0, 1) * 0.6\n",
    "  heatmap = cmap(cam_np)\n",
    "  heatmap[..., 3] = mask * alpha\n",
    "  return img_np,heatmap\n",
    "\n",
    "## Mostrando por classe como fica a verificação\n",
    "def get_cams_per_class(model,loader,target_layer,n_perclass = 5,threshold=60,alpha=0.9):\n",
    "  cam_imgs_per_class = []\n",
    "  for i in range(len(classes)):\n",
    "    cam_imgs_per_class.append([])\n",
    "  loop = True\n",
    "  loader_iter = iter(loader)\n",
    "  while loop:\n",
    "    images_batch, labels_batch, captions_batch = next(loader_iter)\n",
    "    images_batch = images_batch.to(device, non_blocking=True)\n",
    "    labels_batch = labels_batch.to(device, non_blocking=True)\n",
    "\n",
    "    loop = False\n",
    "    for idx in range(len(images_batch)):\n",
    "      label = int(labels_batch[idx].cpu())\n",
    "      if len(cam_imgs_per_class[label]) >= n_perclass: ## já tem o suficiente\n",
    "        continue\n",
    "\n",
    "      loop = True\n",
    "      input_tensor = images_batch[idx].unsqueeze(0).clone().detach().to(device)\n",
    "      input_tensor.requires_grad_(True)\n",
    "      caption = captions_batch[idx]\n",
    "      img_np,heatmap = get_cam_img(model,target_layer,input_tensor,threshold=threshold,alpha = alpha)\n",
    "      output = model(input_tensor)\n",
    "      _, pred = torch.max(output, dim=1)\n",
    "      cam_imgs_per_class[label].append((img_np,heatmap,caption,label,int(pred)))\n",
    "  return cam_imgs_per_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14887084",
   "metadata": {},
   "source": [
    "### Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaca0ce9",
   "metadata": {},
   "source": [
    "Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c32358",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, df, root_dir, transform=None, label_map=None,\n",
    "                 file_column='file',label_column='label',caption_column='caption'):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.label_map = label_map\n",
    "        self.file_column=file_column\n",
    "        self.label_column=label_column\n",
    "        self.caption_column=caption_column\n",
    "\n",
    "        if file_column not in df.columns or label_column not in df.columns:\n",
    "            raise ValueError(\"Precisa das colunas de label e nome do arquivo\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        row = self.df.iloc[idx]\n",
    "        img_name = row[self.file_column]\n",
    "        label = row[self.label_column]\n",
    "        caption = row[self.caption_column]\n",
    "\n",
    "        ## Abre a imagem\n",
    "        img_path = os.path.join(self.root_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        # Converte label se necessário\n",
    "        if self.label_map is not None:\n",
    "            label = self.label_map[label]\n",
    "        else:\n",
    "            label = int(label)\n",
    "\n",
    "        # Aplica transform se houver\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label, caption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9428f6ba",
   "metadata": {},
   "source": [
    "SimpleCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "39af4e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10, dropout_conv=0.3, dropout_fc=0.5):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_classes (int): número de classes na saída.\n",
    "            dropout_conv (float): probabilidade de dropout após blocos de conv (opcional).\n",
    "            dropout_fc (float): probabilidade de dropout nas camadas fully-connected.\n",
    "        \"\"\"\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(p=dropout_conv)\n",
    "        )\n",
    "\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout2d(p=dropout_conv)\n",
    "        )\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_fc),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a63504cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10, pretrained=True, dropout_fc=0.5):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_classes (int): número de classes na saída.\n",
    "            pretrained (bool): se deve carregar pesos pré-treinados da ResNet50.\n",
    "            dropout_fc (float): probabilidade de dropout nas camadas fully-connected.\n",
    "        \"\"\"\n",
    "        super(ResnetCNN, self).__init__()\n",
    "\n",
    "        ## tirando o backbone da resnet e deixando pra ele não treinar\n",
    "        resnet = models.resnet50(pretrained=pretrained)\n",
    "        for param in resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.backbone = nn.Sequential(*list(resnet.children())[:-2]) ## tira as ultimas camadas\n",
    "\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        in_features = resnet.fc.in_features\n",
    "\n",
    "        ## parte do classificador\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout_fc),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.adaptive_pool(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ef44b9",
   "metadata": {},
   "source": [
    "## Parte 2: Configuração e Análise do Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1d0e18",
   "metadata": {},
   "source": [
    "Para este trabalho estamos utilizando o Flickr 8k Dataset\n",
    "\n",
    "Vamos contruir nosso dataframe primeiro antes de manipular qualquer coisa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b901f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A child in a pink dress is climbing up a set o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A girl going into a wooden building .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A little girl climbing into a wooden playhouse .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A little girl climbing the stairs to her playh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A little girl in a pink dress going into a woo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       image  \\\n",
       "0  1000268201_693b08cb0e.jpg   \n",
       "1  1000268201_693b08cb0e.jpg   \n",
       "2  1000268201_693b08cb0e.jpg   \n",
       "3  1000268201_693b08cb0e.jpg   \n",
       "4  1000268201_693b08cb0e.jpg   \n",
       "\n",
       "                                             caption  \n",
       "0  A child in a pink dress is climbing up a set o...  \n",
       "1              A girl going into a wooden building .  \n",
       "2   A little girl climbing into a wooden playhouse .  \n",
       "3  A little girl climbing the stairs to her playh...  \n",
       "4  A little girl in a pink dress going into a woo...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data_path = './data/raw/flickr8k'\n",
    "\n",
    "# Criando nosso dataframe inicial\n",
    "df = pd.read_csv(raw_data_path+'/captions.txt',sep=',',header=None,skiprows=1,names=['image', 'caption'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbf41c8",
   "metadata": {},
   "source": [
    "Note que há muito texto de baixa utilidade nas captions, precisamos limpar primeiro antes de utilizar, para isso, vamos utilizar algumas ferramentas do NLTK\n",
    "\n",
    "Teste do NLTK em extração de stopwords de strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c4f90e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampl sentenc test remov stopword stem\n",
      "anoth exampl nltk base preprocess\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    examples = [\n",
    "        \"This is a sample sentence, to test removal of stopwords and stemming.\",\n",
    "        \"Another example: NLTK-based preprocessing!\"\n",
    "    ]\n",
    "    for s in examples:\n",
    "        print(clean_text(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3a361a",
   "metadata": {},
   "source": [
    "Utilizando este extrator, vamos limpar nossas captions para serem mais utilizáveis com o modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "247e595f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>caption</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A child in a pink dress is climbing up a set o...</td>\n",
       "      <td>child pink dress climb set stair entri way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A girl going into a wooden building .</td>\n",
       "      <td>girl go wooden build</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A little girl climbing into a wooden playhouse .</td>\n",
       "      <td>littl girl climb wooden playhous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A little girl climbing the stairs to her playh...</td>\n",
       "      <td>littl girl climb stair playhous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A little girl in a pink dress going into a woo...</td>\n",
       "      <td>littl girl pink dress go wooden cabin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       image  \\\n",
       "0  1000268201_693b08cb0e.jpg   \n",
       "1  1000268201_693b08cb0e.jpg   \n",
       "2  1000268201_693b08cb0e.jpg   \n",
       "3  1000268201_693b08cb0e.jpg   \n",
       "4  1000268201_693b08cb0e.jpg   \n",
       "\n",
       "                                             caption  \\\n",
       "0  A child in a pink dress is climbing up a set o...   \n",
       "1              A girl going into a wooden building .   \n",
       "2   A little girl climbing into a wooden playhouse .   \n",
       "3  A little girl climbing the stairs to her playh...   \n",
       "4  A little girl in a pink dress going into a woo...   \n",
       "\n",
       "                                      cleaned  \n",
       "0  child pink dress climb set stair entri way  \n",
       "1                        girl go wooden build  \n",
       "2            littl girl climb wooden playhous  \n",
       "3             littl girl climb stair playhous  \n",
       "4       littl girl pink dress go wooden cabin  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned'] = df['caption'].apply(clean_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67697c3",
   "metadata": {},
   "source": [
    "Vamos processar as captions com o CountVectorizer para extrair uma array utilizável de indexadores codificados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c03953b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['08' '10' '104' ... 'zone' 'zoo' 'zoom']\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df['cleaned'].to_list())\n",
    "names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# print(*names, sep=\"\\n\")\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4451e990",
   "metadata": {},
   "source": [
    "Com isso, conseguimos extrair a frequência das palavras em nosso dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2780ec33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dog' 'man' 'two' ... 'loav' 'loader' '08']\n",
      "dog       10263\n",
      "man        7284\n",
      "two        5643\n",
      "boy        4247\n",
      "girl       4172\n",
      "white      3960\n",
      "black      3848\n",
      "woman      3402\n",
      "run        3367\n",
      "play       3340\n",
      "wear       3226\n",
      "stand      3175\n",
      "jump       2891\n",
      "peopl      2885\n",
      "water      2825\n",
      "red        2692\n",
      "young      2630\n",
      "brown      2578\n",
      "sit        2305\n",
      "blue       2282\n",
      "shirt      2099\n",
      "walk       2040\n",
      "hold       1883\n",
      "ball       1849\n",
      "littl      1768\n",
      "grass      1626\n",
      "ride       1620\n",
      "snow       1558\n",
      "person     1546\n",
      "child      1546\n",
      "look       1520\n",
      "three      1387\n"
     ]
    }
   ],
   "source": [
    "somado = np.sum(X.toarray(),axis=0)\n",
    "idxs = np.argsort(somado)[::-1]\n",
    "print(names[idxs])\n",
    "nomes = {names[idx]:somado[idx] for idx in idxs}\n",
    "\n",
    "for i,(k,v) in enumerate(nomes.items()):\n",
    "  print(f\"{k:10}{v:5}\")\n",
    "  if i>30:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e58bf4",
   "metadata": {},
   "source": [
    "Utilizaremos os classificadores que identificarão \"cachorros, homens, mulheres, crianças, água, bolas, carros e neve\" para nossos modelos deste trabalho\n",
    "\n",
    "Os dez classificadores que usaremos são objetos de alta frequência destas imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcc5c536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>caption</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>in_class</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A child in a pink dress is climbing up a set o...</td>\n",
       "      <td>child pink dress climb set stair entri way</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1001773457_577c3a7d70.jpg</td>\n",
       "      <td>A black dog and a spotted dog are fighting</td>\n",
       "      <td>black dog spot dog fight</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1001773457_577c3a7d70.jpg</td>\n",
       "      <td>A black dog and a tri-colored dog playing with...</td>\n",
       "      <td>black dog tri color dog play road</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1001773457_577c3a7d70.jpg</td>\n",
       "      <td>A black dog and a white dog with brown spots a...</td>\n",
       "      <td>black dog white dog brown spot stare street</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1001773457_577c3a7d70.jpg</td>\n",
       "      <td>Two dogs of different breeds looking at each o...</td>\n",
       "      <td>two dog differ breed look road</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1001773457_577c3a7d70.jpg</td>\n",
       "      <td>Two dogs on pavement moving toward each other .</td>\n",
       "      <td>two dog pavement move toward</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1003163366_44323f5815.jpg</td>\n",
       "      <td>A man lays on a bench while his dog sits by him .</td>\n",
       "      <td>man lay bench dog sit</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1003163366_44323f5815.jpg</td>\n",
       "      <td>A man lays on the bench to which a white dog i...</td>\n",
       "      <td>man lay bench white dog also tie</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1003163366_44323f5815.jpg</td>\n",
       "      <td>a man sleeping on a bench outside with a white...</td>\n",
       "      <td>man sleep bench outsid white black dog sit next</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1003163366_44323f5815.jpg</td>\n",
       "      <td>A shirtless man lies on a park bench with his ...</td>\n",
       "      <td>shirtless man lie park bench dog</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1003163366_44323f5815.jpg</td>\n",
       "      <td>man laying on bench holding leash of dog sitti...</td>\n",
       "      <td>man lay bench hold leash dog sit ground</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1007129816_e794419615.jpg</td>\n",
       "      <td>A man in an orange hat starring at something .</td>\n",
       "      <td>man orang hat star someth</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1007129816_e794419615.jpg</td>\n",
       "      <td>A man wears an orange hat and glasses .</td>\n",
       "      <td>man wear orang hat glass</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1007129816_e794419615.jpg</td>\n",
       "      <td>A man with gauges and glasses is wearing a Bli...</td>\n",
       "      <td>man gaug glass wear blitz hat</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1007129816_e794419615.jpg</td>\n",
       "      <td>A man with glasses is wearing a beer can croch...</td>\n",
       "      <td>man glass wear beer crochet hat</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1007129816_e794419615.jpg</td>\n",
       "      <td>The man with pierced ears is wearing glasses a...</td>\n",
       "      <td>man pierc ear wear glass orang hat</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1007320043_627395c3d8.jpg</td>\n",
       "      <td>A child playing on a rope net .</td>\n",
       "      <td>child play rope net</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1007320043_627395c3d8.jpg</td>\n",
       "      <td>A small child grips onto the red ropes at the ...</td>\n",
       "      <td>small child grip onto red rope playground</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1007320043_627395c3d8.jpg</td>\n",
       "      <td>The small child climbs on a red ropes on a pla...</td>\n",
       "      <td>small child climb red rope playground</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1009434119_febe49276a.jpg</td>\n",
       "      <td>A black and white dog is running in a grassy g...</td>\n",
       "      <td>black white dog run grassi garden surround whi...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1009434119_febe49276a.jpg</td>\n",
       "      <td>A black and white dog is running through the g...</td>\n",
       "      <td>black white dog run grass</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1009434119_febe49276a.jpg</td>\n",
       "      <td>A dog runs on the green grass near a wooden fe...</td>\n",
       "      <td>dog run green grass near wooden fenc</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1012212859_01547e3f17.jpg</td>\n",
       "      <td>A dog shakes its head near the shore , a red b...</td>\n",
       "      <td>dog shake head near shore red ball next</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1012212859_01547e3f17.jpg</td>\n",
       "      <td>A white dog shakes on the edge of a beach with...</td>\n",
       "      <td>white dog shake edg beach orang ball</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1012212859_01547e3f17.jpg</td>\n",
       "      <td>Dog with orange ball at feet , stands on shore...</td>\n",
       "      <td>dog orang ball feet stand shore shake water</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        image  \\\n",
       "0   1000268201_693b08cb0e.jpg   \n",
       "5   1001773457_577c3a7d70.jpg   \n",
       "6   1001773457_577c3a7d70.jpg   \n",
       "7   1001773457_577c3a7d70.jpg   \n",
       "8   1001773457_577c3a7d70.jpg   \n",
       "9   1001773457_577c3a7d70.jpg   \n",
       "15  1003163366_44323f5815.jpg   \n",
       "16  1003163366_44323f5815.jpg   \n",
       "17  1003163366_44323f5815.jpg   \n",
       "18  1003163366_44323f5815.jpg   \n",
       "19  1003163366_44323f5815.jpg   \n",
       "20  1007129816_e794419615.jpg   \n",
       "21  1007129816_e794419615.jpg   \n",
       "22  1007129816_e794419615.jpg   \n",
       "23  1007129816_e794419615.jpg   \n",
       "24  1007129816_e794419615.jpg   \n",
       "25  1007320043_627395c3d8.jpg   \n",
       "28  1007320043_627395c3d8.jpg   \n",
       "29  1007320043_627395c3d8.jpg   \n",
       "30  1009434119_febe49276a.jpg   \n",
       "31  1009434119_febe49276a.jpg   \n",
       "34  1009434119_febe49276a.jpg   \n",
       "35  1012212859_01547e3f17.jpg   \n",
       "36  1012212859_01547e3f17.jpg   \n",
       "37  1012212859_01547e3f17.jpg   \n",
       "\n",
       "                                              caption  \\\n",
       "0   A child in a pink dress is climbing up a set o...   \n",
       "5          A black dog and a spotted dog are fighting   \n",
       "6   A black dog and a tri-colored dog playing with...   \n",
       "7   A black dog and a white dog with brown spots a...   \n",
       "8   Two dogs of different breeds looking at each o...   \n",
       "9     Two dogs on pavement moving toward each other .   \n",
       "15  A man lays on a bench while his dog sits by him .   \n",
       "16  A man lays on the bench to which a white dog i...   \n",
       "17  a man sleeping on a bench outside with a white...   \n",
       "18  A shirtless man lies on a park bench with his ...   \n",
       "19  man laying on bench holding leash of dog sitti...   \n",
       "20     A man in an orange hat starring at something .   \n",
       "21            A man wears an orange hat and glasses .   \n",
       "22  A man with gauges and glasses is wearing a Bli...   \n",
       "23  A man with glasses is wearing a beer can croch...   \n",
       "24  The man with pierced ears is wearing glasses a...   \n",
       "25                    A child playing on a rope net .   \n",
       "28  A small child grips onto the red ropes at the ...   \n",
       "29  The small child climbs on a red ropes on a pla...   \n",
       "30  A black and white dog is running in a grassy g...   \n",
       "31  A black and white dog is running through the g...   \n",
       "34  A dog runs on the green grass near a wooden fe...   \n",
       "35  A dog shakes its head near the shore , a red b...   \n",
       "36  A white dog shakes on the edge of a beach with...   \n",
       "37  Dog with orange ball at feet , stands on shore...   \n",
       "\n",
       "                                              cleaned  in_class  label  \n",
       "0          child pink dress climb set stair entri way      True      3  \n",
       "5                            black dog spot dog fight      True      0  \n",
       "6                   black dog tri color dog play road      True      0  \n",
       "7         black dog white dog brown spot stare street      True      0  \n",
       "8                      two dog differ breed look road      True      0  \n",
       "9                        two dog pavement move toward      True      0  \n",
       "15                              man lay bench dog sit      True      1  \n",
       "16                   man lay bench white dog also tie      True      1  \n",
       "17    man sleep bench outsid white black dog sit next      True      1  \n",
       "18                   shirtless man lie park bench dog      True      1  \n",
       "19            man lay bench hold leash dog sit ground      True      1  \n",
       "20                          man orang hat star someth      True      1  \n",
       "21                           man wear orang hat glass      True      1  \n",
       "22                      man gaug glass wear blitz hat      True      1  \n",
       "23                    man glass wear beer crochet hat      True      1  \n",
       "24                 man pierc ear wear glass orang hat      True      1  \n",
       "25                                child play rope net      True      3  \n",
       "28          small child grip onto red rope playground      True      3  \n",
       "29              small child climb red rope playground      True      3  \n",
       "30  black white dog run grassi garden surround whi...      True      0  \n",
       "31                          black white dog run grass      True      0  \n",
       "34               dog run green grass near wooden fenc      True      0  \n",
       "35            dog shake head near shore red ball next      True      0  \n",
       "36               white dog shake edg beach orang ball      True      0  \n",
       "37        dog orang ball feet stand shore shake water      True      0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As classes são valores de alta frequência que encontramos no dataset\n",
    "classes = ['dog','man','woman','child','water','ball','car','snow']\n",
    "class2label = {classes[i]:i for i in range(len(classes))}\n",
    "label2class = {i:classes[i] for i in range(len(classes))}\n",
    "\n",
    "# Vamos criar um novo dataframe, agora, com os labels das classes que serão avaliadas\n",
    "df['in_class'] = df['cleaned'].apply(lambda x: any([word in classes for word in x.split()]))\n",
    "df_filtered = df[df['in_class']].copy()\n",
    "df_filtered['label'] = df_filtered['cleaned'].apply(lambda x: [class2label[word] for word in x.split() if word in classes][0])\n",
    "\n",
    "df_filtered.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0cebfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes_counts = df_filtered['label'].value_counts().sort_values(ascending=False)\n",
    "\n",
    "sns.set_palette(\"tab10\", 10)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(5, 4))\n",
    "sns.barplot(x=classes, y=classes_counts.values, alpha=0.8, hue=classes_counts.index, palette=\"tab10\", ax=axes, legend=False)\n",
    "\n",
    "axes.set_title('Classificadores Encontrados', fontsize=16)\n",
    "axes.set_xlabel('Classe', fontsize=14)\n",
    "axes.set_ylabel('Quantidade', fontsize=14)\n",
    "axes.set_xticks(classes)\n",
    "axes.set_xticklabels(classes, rotation=15)\n",
    "fig.subplots_adjust(top=0.7, right=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "aff8b49b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>caption</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>in_class</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38912</th>\n",
       "      <td>590445887_4d4fa43923.jpg</td>\n",
       "      <td>A woman with green hair hula hoops before a cr...</td>\n",
       "      <td>woman green hair hula hoop crowd</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26625</th>\n",
       "      <td>3372340429_91c4f4af30.jpg</td>\n",
       "      <td>a few dogs jumping around in the snow</td>\n",
       "      <td>dog jump around snow</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14338</th>\n",
       "      <td>2759089516_cbb993cb92.jpg</td>\n",
       "      <td>A child wearing pink soled sneakers is climbin...</td>\n",
       "      <td>child wear pink sole sneaker climb headfirst w...</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6148</th>\n",
       "      <td>2209496328_2a34fd201d.jpg</td>\n",
       "      <td>A white dog swims through the water with a red...</td>\n",
       "      <td>white dog swim water red toy</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38919</th>\n",
       "      <td>597543181_6a85ef4c17.jpg</td>\n",
       "      <td>a young child swinging on a green swing .</td>\n",
       "      <td>young child swing green swing</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image  \\\n",
       "38912   590445887_4d4fa43923.jpg   \n",
       "26625  3372340429_91c4f4af30.jpg   \n",
       "14338  2759089516_cbb993cb92.jpg   \n",
       "6148   2209496328_2a34fd201d.jpg   \n",
       "38919   597543181_6a85ef4c17.jpg   \n",
       "\n",
       "                                                 caption  \\\n",
       "38912  A woman with green hair hula hoops before a cr...   \n",
       "26625              a few dogs jumping around in the snow   \n",
       "14338  A child wearing pink soled sneakers is climbin...   \n",
       "6148   A white dog swims through the water with a red...   \n",
       "38919          a young child swinging on a green swing .   \n",
       "\n",
       "                                                 cleaned  in_class  label  \n",
       "38912                   woman green hair hula hoop crowd      True      2  \n",
       "26625                               dog jump around snow      True      0  \n",
       "14338  child wear pink sole sneaker climb headfirst w...      True      3  \n",
       "6148                        white dog swim water red toy      True      0  \n",
       "38919                      young child swing green swing      True      3  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = 1000\n",
    "samples_per_class = int(n_samples/df_filtered['label'].nunique())\n",
    "samples_indexes = set()\n",
    "for label in df_filtered['label'].unique():\n",
    "  indexes = np.array(df_filtered[df_filtered['label']==label].sample(samples_per_class).index)\n",
    "  samples_indexes = samples_indexes.union(set(indexes))\n",
    "\n",
    "samples_indexes = list(samples_indexes)\n",
    "df_samples = df_filtered.loc[samples_indexes]\n",
    "df_samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "414dd7d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "classes_counts = np.array(df_samples['label'].value_counts().to_list())\n",
    "plt.bar(np.arange(len(classes)),classes_counts)\n",
    "plt.xticks(np.arange(len(classes)),classes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "af281b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>caption</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>590445887_4d4fa43923.jpg</td>\n",
       "      <td>A woman with green hair hula hoops before a cr...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3372340429_91c4f4af30.jpg</td>\n",
       "      <td>a few dogs jumping around in the snow</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2759089516_cbb993cb92.jpg</td>\n",
       "      <td>A child wearing pink soled sneakers is climbin...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2209496328_2a34fd201d.jpg</td>\n",
       "      <td>A white dog swims through the water with a red...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>597543181_6a85ef4c17.jpg</td>\n",
       "      <td>a young child swinging on a green swing .</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>584484388_0eeb36d03d.jpg</td>\n",
       "      <td>Two little wiener dogs are running on the gras...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2890057168_c712f932e0.jpg</td>\n",
       "      <td>Two adults and a child wait to cross a street .</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2623146491_b64698b875.jpg</td>\n",
       "      <td>Man standing at a check-out counter .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>3210359094_ee51285301.jpg</td>\n",
       "      <td>A child playing in snow .</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>3210359094_ee51285301.jpg</td>\n",
       "      <td>A little girl sitting in the snow</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         image  \\\n",
       "0     590445887_4d4fa43923.jpg   \n",
       "1    3372340429_91c4f4af30.jpg   \n",
       "2    2759089516_cbb993cb92.jpg   \n",
       "3    2209496328_2a34fd201d.jpg   \n",
       "4     597543181_6a85ef4c17.jpg   \n",
       "..                         ...   \n",
       "995   584484388_0eeb36d03d.jpg   \n",
       "996  2890057168_c712f932e0.jpg   \n",
       "997  2623146491_b64698b875.jpg   \n",
       "998  3210359094_ee51285301.jpg   \n",
       "999  3210359094_ee51285301.jpg   \n",
       "\n",
       "                                               caption  label  \n",
       "0    A woman with green hair hula hoops before a cr...      2  \n",
       "1                a few dogs jumping around in the snow      0  \n",
       "2    A child wearing pink soled sneakers is climbin...      3  \n",
       "3    A white dog swims through the water with a red...      0  \n",
       "4            a young child swinging on a green swing .      3  \n",
       "..                                                 ...    ...  \n",
       "995  Two little wiener dogs are running on the gras...      0  \n",
       "996    Two adults and a child wait to cross a street .      3  \n",
       "997              Man standing at a check-out counter .      1  \n",
       "998                          A child playing in snow .      3  \n",
       "999                  A little girl sitting in the snow      7  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_samples.columns\n",
    "df_samples.index\n",
    "type(df_samples.iloc[0]['label'])\n",
    "df_samples = df_samples.reset_index()\n",
    "df_samples = df_samples[['image', 'caption', 'label']]\n",
    "#df_samples['label'] = df_samples['label'].astype(float) \n",
    "df_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcb5ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dim = (224,224) ## bota as imagens para uma dimensão só\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(image_dim),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "flickr8k_cleaned = ImageDataset(df_samples, raw_data_path+'/Images', file_column='image',transform=transform)\n",
    "print(f\"image data: {flickr8k_cleaned[0][0][0]}\")\n",
    "print(f\"label: {flickr8k_cleaned[0][1]}\")\n",
    "print(f\"caption: {flickr8k_cleaned[0][2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118bdd80",
   "metadata": {},
   "source": [
    "#### Preparação para treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "34e1cc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = torch.utils.data.random_split(flickr8k_cleaned, [0.8, 0.2])\n",
    "save_dir = './data/processed'\n",
    "torch.save(flickr8k_cleaned, save_dir+'/mini_flickr8k.pt')\n",
    "torch.save(train, save_dir+'/train_subset.pt')\n",
    "torch.save(test, save_dir+'/test_subset.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a490a798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.7961, 0.7961, 0.7961,  ..., 0.8000, 0.7961, 0.8000],\n",
       "          [0.7098, 0.7020, 0.6980,  ..., 0.8510, 0.8510, 0.8392],\n",
       "          [0.0706, 0.0588, 0.0588,  ..., 0.5686, 0.5686, 0.5569],\n",
       "          ...,\n",
       "          [0.6667, 0.6745, 0.6784,  ..., 0.6941, 0.6902, 0.6902],\n",
       "          [0.6549, 0.6431, 0.6627,  ..., 0.6941, 0.6863, 0.6784],\n",
       "          [0.6863, 0.6784, 0.6627,  ..., 0.6980, 0.7020, 0.6980]],\n",
       " \n",
       "         [[0.7961, 0.7961, 0.7961,  ..., 0.8000, 0.7961, 0.8000],\n",
       "          [0.7098, 0.7020, 0.6980,  ..., 0.8510, 0.8510, 0.8392],\n",
       "          [0.0706, 0.0627, 0.0588,  ..., 0.5647, 0.5647, 0.5529],\n",
       "          ...,\n",
       "          [0.6588, 0.6667, 0.6745,  ..., 0.6824, 0.6784, 0.6784],\n",
       "          [0.6314, 0.6275, 0.6549,  ..., 0.6863, 0.6784, 0.6667],\n",
       "          [0.6824, 0.6706, 0.6588,  ..., 0.6941, 0.6980, 0.6941]],\n",
       " \n",
       "         [[0.7961, 0.7961, 0.7961,  ..., 0.8000, 0.8000, 0.8000],\n",
       "          [0.7059, 0.7020, 0.6980,  ..., 0.8588, 0.8588, 0.8471],\n",
       "          [0.0549, 0.0471, 0.0471,  ..., 0.5843, 0.5843, 0.5765],\n",
       "          ...,\n",
       "          [0.6863, 0.6980, 0.6941,  ..., 0.7098, 0.7059, 0.7020],\n",
       "          [0.6549, 0.6627, 0.6824,  ..., 0.7059, 0.6980, 0.6941],\n",
       "          [0.6863, 0.6902, 0.6824,  ..., 0.7098, 0.7098, 0.7059]]]),\n",
       " 7,\n",
       " 'Two white standard poodles playing tug of war in the snow .')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.load(save_dir+'/mini_flickr8k.pt', weights_only=False)\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(data, [0.75, 0.125, 0.125])\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0942a9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fazendo os loaders\n",
    "batch_size = 32\n",
    "num_workers = 4\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                          num_workers=num_workers, pin_memory=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False,\n",
    "                          num_workers=num_workers, pin_memory=True)\n",
    "test_loader   = DataLoader(test_dataset,   batch_size=batch_size, shuffle=False,\n",
    "                          num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424e04bd",
   "metadata": {},
   "source": [
    "## Parte 3: Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e475b98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "simpleModel = SimpleCNN(num_classes=len(classes)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(simpleModel.parameters(), lr=1e-3)\n",
    "num_epochs = 10\n",
    "\n",
    "train_losses, train_accs, val_losses, val_accs = train(simpleModel,optimizer,criterion,train_loader,val_loader,num_epochs)\n",
    "plot_trainval_graphs(train_losses, train_accs, val_losses, val_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eeef27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, './models/flickrcnn.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03301f9",
   "metadata": {},
   "source": [
    "O modelo está sendo treinado por muito poucas épocas, não é tão potente e não estão sendo feitas técnicas para aumentar a robustez das predições como Data Augmentation, então já era esperado que o modelo não desempenhasse bem. Isso foi praticamente um exemplo didático do funcionamento da cnn.\n",
    "\n",
    "O dataset é bem complicado, então já é esperado que ele não desempenhe bem, mas aparentemente ele está conseguindo acertar mais da classe 'snow' e 'dog'. Dito isso, vamos tentar usar [Class Activation Map](https://github.com/frgfm/torch-cam) para tentar entender o funcionamento interno da rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a496bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_perclass = 5\n",
    "figsize = (5,5)\n",
    "cam_imgs_per_class = get_cams_per_class(model,train_loader,n_perclass = n_perclass,target_layer='block1')\n",
    "\n",
    "for class_idx, cams_imgs in enumerate(cam_imgs_per_class):\n",
    "  fig,axs = plt.subplots(1,5,figsize=(figsize[0]*n_perclass,figsize[1]*1))\n",
    "\n",
    "  ## mostra as imagens nos ax\n",
    "  for img_count, (img_np,heatmap,caption,label,pred) in enumerate(cams_imgs):\n",
    "    ax = axs[img_count]\n",
    "    ax.imshow(img_np)\n",
    "    ax.imshow(heatmap)\n",
    "    ax.set_title(f\"img {img_count}\")\n",
    "    ax.axis('off')\n",
    "  fig.suptitle(f\"CAM para a classe {label2class[class_idx]}\")\n",
    "  plt.show()\n",
    "\n",
    "  ## printa as captions e labels e preds\n",
    "  for img_count, (img_np,heatmap,caption,label,pred) in enumerate(cams_imgs):\n",
    "    true_class = label2class[label]\n",
    "    pred_class = label2class[pred]\n",
    "    print(f\"{img_count:5} --- true: {true_class:10} pred: {pred_class:10} caption: {caption}\")\n",
    "  print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07d824f",
   "metadata": {},
   "source": [
    "## Parte 4: Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2890eebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['dog','man','woman','child','water','ball','car','snow']\n",
    "class2label = {classes[i]:i for i in range(len(classes))}\n",
    "label2class = {i:classes[i] for i in range(len(classes))}\n",
    "\n",
    "#carregando dataset\n",
    "whole_train_data = torch.load('./data/processed/train_subset.pt', weights_only=False)\n",
    "train_dataset, val_dataset= torch.utils.data.random_split(whole_train_data, [0.8, 0.2])\n",
    "\n",
    "## Fazendo os loaders\n",
    "batch_size = 32\n",
    "num_workers = 4\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                          num_workers=num_workers, pin_memory=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False,\n",
    "                          num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7368670",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet = ResnetCNN(num_classes=len(classes)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_resnet.parameters(), lr=1e-3)\n",
    "num_epochs = 30\n",
    "\n",
    "train_losses, train_accs, val_losses, val_accs = train(model_resnet,optimizer,criterion,train_loader,val_loader,num_epochs, device=device)\n",
    "plot_trainval_graphs(train_losses, train_accs, val_losses, val_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4735f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model_resnet, './models/resnet_based.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bffeeb9",
   "metadata": {},
   "source": [
    "## Parte 5: Validação dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2bbe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definindo classes\n",
    "classes = ['dog','man','woman','child','water','ball','car','snow']\n",
    "class2label = {classes[i]:i for i in range(len(classes))}\n",
    "label2class = {i:classes[i] for i in range(len(classes))}\n",
    "\n",
    "#carregando modelos\n",
    "simple_model = torch.load('./models/flickrcnn.pt', weights_only=False, map_location=torch.device(device))\n",
    "resnet_model = torch.load('./models/resnet_based.pt', weights_only=False, map_location=torch.device(device))\n",
    "\n",
    "#carregando dataset\n",
    "whole_train_data = torch.load('./data/processed/train_subset.pt', weights_only=False)\n",
    "test_dataset = torch.load('./data/processed/test_subset.pt', weights_only=False)\n",
    "train_dataset, val_dataset= torch.utils.data.random_split(whole_train_data, [0.8, 0.2])\n",
    "\n",
    "## Fazendo os loaders\n",
    "batch_size = 32\n",
    "num_workers = 4\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                          num_workers=num_workers, pin_memory=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False,\n",
    "                          num_workers=num_workers, pin_memory=True)\n",
    "test_loader   = DataLoader(test_dataset,   batch_size=batch_size, shuffle=False,\n",
    "                          num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1054cd",
   "metadata": {},
   "source": [
    "### Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dbcda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acc_per_class(simple_model,(train_loader,val_loader,test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a237d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_perclass = 5\n",
    "figsize = (5,5)\n",
    "cam_imgs_per_class = get_cams_per_class(simple_model,train_loader,n_perclass = n_perclass,target_layer='block1')\n",
    "\n",
    "for class_idx, cams_imgs in enumerate(cam_imgs_per_class):\n",
    "  fig,axs = plt.subplots(1,5,figsize=(figsize[0]*n_perclass,figsize[1]*1))\n",
    "\n",
    "  ## mostra as imagens nos ax\n",
    "  for img_count, (img_np,heatmap,caption,label,pred) in enumerate(cams_imgs):\n",
    "    ax = axs[img_count]\n",
    "    ax.imshow(img_np)\n",
    "    ax.imshow(heatmap)\n",
    "    ax.set_title(f\"img {img_count}\")\n",
    "    ax.axis('off')\n",
    "  fig.suptitle(f\"CAM para a classe {label2class[class_idx]}\")\n",
    "  plt.show()\n",
    "\n",
    "  ## printa as captions e labels e preds\n",
    "  for img_count, (img_np,heatmap,caption,label,pred) in enumerate(cams_imgs):\n",
    "    true_class = label2class[label]\n",
    "    pred_class = label2class[pred]\n",
    "    print(f\"{img_count:5} --- true: {true_class:10} pred: {pred_class:10} caption: {caption}\")\n",
    "  print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86b7bc6",
   "metadata": {},
   "source": [
    "### Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408e0c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acc_per_class(resnet_model,(train_loader,val_loader,test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c662dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_perclass = 5\n",
    "figsize = (5,5)\n",
    "cam_imgs_per_class = get_cams_per_class(resnet_model,train_loader,n_perclass = n_perclass,target_layer=resnet_model.backbone[-1])\n",
    "\n",
    "for class_idx, cams_imgs in enumerate(cam_imgs_per_class):\n",
    "  fig,axs = plt.subplots(1,5,figsize=(figsize[0]*n_perclass,figsize[1]*1))\n",
    "\n",
    "  ## mostra as imagens nos ax\n",
    "  for img_count, (img_np,heatmap,caption,label,pred) in enumerate(cams_imgs):\n",
    "    ax = axs[img_count]\n",
    "    ax.imshow(img_np)\n",
    "    ax.imshow(heatmap)\n",
    "    ax.set_title(f\"img {img_count}\")\n",
    "    ax.axis('off')\n",
    "  fig.suptitle(f\"CAM para a classe {label2class[class_idx]}\")\n",
    "  plt.show()\n",
    "\n",
    "  ## printa as captions e labels e preds\n",
    "  for img_count, (img_np,heatmap,caption,label,pred) in enumerate(cams_imgs):\n",
    "    true_class = label2class[label]\n",
    "    pred_class = label2class[pred]\n",
    "    print(f\"{img_count:5} --- true: {true_class:10} pred: {pred_class:10} caption: {caption}\")\n",
    "  print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5379f6ce",
   "metadata": {},
   "source": [
    "Bom, com certeza os filtros estão melhores que na SimpleCNN. Mas como verificamos overfitting antes, vamos tentar ver o quanto isso influencia nos dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03485db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_perclass = 5\n",
    "figsize = (5,5)\n",
    "cam_imgs_per_class = get_cams_per_class(resnet_model,test_loader,n_perclass = n_perclass,target_layer=resnet_model.backbone[-1])\n",
    "\n",
    "for class_idx, cams_imgs in enumerate(cam_imgs_per_class):\n",
    "  fig,axs = plt.subplots(1,5,figsize=(figsize[0]*n_perclass,figsize[1]*1))\n",
    "\n",
    "  ## mostra as imagens nos ax\n",
    "  for img_count, (img_np,heatmap,caption,label,pred) in enumerate(cams_imgs):\n",
    "    ax = axs[img_count]\n",
    "    ax.imshow(img_np)\n",
    "    ax.imshow(heatmap)\n",
    "    ax.set_title(f\"img {img_count}\")\n",
    "    ax.axis('off')\n",
    "  fig.suptitle(f\"CAM para a classe {label2class[class_idx]}\")\n",
    "  plt.show()\n",
    "\n",
    "  ## printa as captions e labels e preds\n",
    "  for img_count, (img_np,heatmap,caption,label,pred) in enumerate(cams_imgs):\n",
    "    true_class = label2class[label]\n",
    "    pred_class = label2class[pred]\n",
    "    print(f\"{img_count:5} --- true: {true_class:10} pred: {pred_class:10} caption: {caption}\")\n",
    "  print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7808cb",
   "metadata": {},
   "source": [
    "Parece que a coloração dos objetos ainda interfere e isso pode estar atrapalhando (por exemplo uma criança de camisa branca ser confundida com 'snow').\n",
    "\n",
    "Apesar disso, existem vários casos que a rede desempenhou bem já que conseguiu achar até casos multilabel, como 'duas crianças brincando na água' (nesse exemplo ela prediz 'child', mas pela construção do dataset, seria 'water', mas a interpretação está ótima)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
